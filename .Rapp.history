library(arab)
library(NBPSeq)
data(arab)
head(arab)
require(reshape)
n <- 0
base::source("/tmp/r-plugin-mig/Rsource-3266-Monte-Hall.R")
base::source("/tmp/r-plugin-mig/Rsource-3266-kmeans.R")
install.packages("Vennerable", repos="http://R-Forge.R-project.org")
source("http://bioconductor.org/biocLite.R")#
    biocLite("graph")
source("http://bioconductor.org/biocLite.R")#
    biocLite("RBGL")
library(Vennerable)
Vcombo <- Venn(SetNames = c("Female", "Visible Minority", "CS Major"), Weight = c(0, 4148, 409, 604, 543, 67, 183, 146))#
plot(Vcombo)
VennCompare = Venn(SetNames = c("NBPSeq", "DESeq", "edgeR"), Weight = c(0, 208, 1, 1, 4, 281, 0, 115))
plot(VennCompare)
?Venn
Venn
VennCompare
plot(VennCompare, type="squares")
plot(VennCompare, type="squares", show = list(FaceText = "weight")
)
plot(VennCompare, show = list(FaceText = "signature", SetLabels = FALSE, Faces = FALSE))
plot(VennCompare, show = list(FaceText = "sets", SetLabels = FALSE, Faces = TRUE))
plot(VennCompare, show = list(FaceText = "sets", SetLabels = TRUE, Faces = TRUE))
plot(VennCompare, show = list(FaceText = "sets", SetLabels = TRUE, Faces = FALSE))
VennCompare = Venn(SetNames = c("NBPSeq", "DESeq", "edgeR"), Weight = c(0, 208, 1, 1, 4, 281, 0, 115), doEuler = FALSE)
plot(VennCompare, doWeights=FALSE, show = list(FaceText = "sets", SetLabels = TRUE, Faces = FALSE))
library(Vennerable)#
Vcombo <- Venn(SetNames = c("Female", "Visible Minority", "CS Major"), Weight = c(0, 4148, 409, 604, 543, 67, 183, 146))#
plot(Vcombo)
VennCompare = Venn(SetNames = c("NBPSeq", "DESeq", "edgeR"), Weight = c(208, 1, 1, 4, 281, 0, 115))
plot(VennCompare, doWeights=FALSE, show = list(FaceText = "sets", SetLabels = TRUE, Faces = FALSE))
plot(Vcombo)
VennCompare = Venn(SetNames = c("NBPSeq", "DESeq", "edgeR"), Weight = c(0, 208, 1, 1, 4, 281, 0, 115))
plot(VennCompare, doWeights=FALSE, show = list(FaceText = "sets", SetLabels = TRUE, Faces = FALSE))
VennCompare = Venn(SetNames = c("NBPSeq", "DESeq", "edgeR"), Weight = c(0, 208, 1, 1, 4, 281, 0, 115))
plot(VennCompare, doWeights=TRUE, show = list(FaceText = "sets", SetLabels = TRUE, Faces = FALSE))
library(venneuler)
plot(venneuler(c(A=1, B=1, C=1, "A&B"=0.5, "A&C"=0.5, "B&C"=0.5 ,"A&B&C"=0.5)))
âƒ	plot(venneuler(c(A=605, B=400, C=117, "A&B"=396, "A&C"=116, "B&C"=115 ,"A&B&C"=115)))
plot(venneuler(c(A=605, B=400, C=117, "A&B"=396, "A&C"=116, "B&C"=115 ,"A&B&C"=115)))
?venneuler
?plot.venneuler
construct some fake gene names..#
oneName <- function() paste(sample(LETTERS,5,replace=TRUE),collapse="")#
geneNames <- replicate(1000, oneName())#
GroupA <- sample(geneNames, 400, replace=FALSE)#
GroupB <- sample(geneNames, 750, replace=FALSE)#
GroupC <- sample(geneNames, 250, replace=FALSE)#
GroupD <- sample(geneNames, 300, replace=FALSE)#
input  <-list(GroupA,GroupB,GroupC,GroupD)#
venn(input)
library(Vennerable)
oneName <- function() paste(sample(LETTERS,5,replace=TRUE),collapse="")#
geneNames <- replicate(1000, oneName())#
GroupA <- sample(geneNames, 400, replace=FALSE)#
GroupB <- sample(geneNames, 750, replace=FALSE)#
GroupC <- sample(geneNames, 250, replace=FALSE)#
GroupD <- sample(geneNames, 300, replace=FALSE)#
input  <-list(GroupA,GroupB,GroupC,GroupD)#
venn(input)
Venn(input)
plot(Venn(input))
VennCompare = Venn(SetNames = c("NBPSeq", "DESeq", "edgeR"), Weight = c(0, 208, 1, 1, 4, 281, 0, 115))#
plot(VennCompare, doWeights=TRUE, show = list(FaceText = "sets", SetLabels = TRUE, Faces = FALSE))
VennCompare
VennCompare = Venn(SetNames = c("NBPSeq", "DESeq", "edgeR"), Weight = c(0, 605, 400, 396, 117, 116, 115, 115))#
VennCompare
plot(VennCompare, doWeights=TRUE, show = list(FaceText = "sets", SetLabels = TRUE, Faces = FALSE))
plot(VennCompare)
plot(VennCompare, doWeights=TRUE, show = list(FaceText = "sets", SetLabels = TRUE, Faces = FALSE))
plot(VennCompare, doWeights=TRUE, show = list(FaceText = "elements", SetLabels = TRUE, Faces = FALSE))
getwd()
require(VennDiagram)#
#
venn.plot <- draw.triple.venn(#
    area1 = 70,#
    area2 = 250,#
    area3 = 500,#
    n12 = 30,#
    n23 = 60,#
    n13 = 10,#
    n123 = 5,#
    category = c("C1", "C2", "C3"),#
    fill = c("blue", "red", "green"),#
    scaled=TRUE)#
#
tiff(filename = "test.tiff", compression = "none",type = "quartz",antialias = "none")#
grid.draw(venn.plot)#
dev.off()
venn.diagram(x=list(A=c(1:15,16:20), B=c(6:15,21:30,100:150), C=c(11:30,200:300)),#
         filename="test.tiff",#
         fill = c("blue", "yellow", "red"), scaled=TRUE)
getwd()
?venn.diagram
venn.diagram(#
	x = list(#
		"Num A" = paste("Num", 1:100),#
		"Num B" = c(paste("Num", 61:70), paste("Num", 71:100)),#
		"Num C" = c(paste("Num", 41:60), paste("Num", 61:70))),#
	euler.d = TRUE,#
	filename = "Euler_3set_simple.tiff",#
	cat.pos = c(-20, 0, 20),#
	cat.dist = c(0.05, 0.05, 0.02),#
	cex = 2.5,#
	cat.cex = 2.5,#
	reverse = TRUE#
	);
vennplot = venn.diagram(x=list(A=c(1:15,16:20), B=c(6:15,21:30,100:150), C=c(11:30,200:300)),#
         filename="test.tiff",#
         fill = c("blue", "yellow", "red"), scaled=TRUE)
grid.draw(vennplot)
library(VennDiagram)#
 draw.triple.venn(10,5,4,2,3,1,1,ind=TRUE,scaled=TRUE)
library(Vennerable)
VennCompare = Venn(SetNames = c("NBPSeq", "DESeq", "edgeR"), Weight = c(0, 605, 400, 396, 117, 116, 115, 115))
plot(VennCompare)
plot(VennCompare, doWeights=FALSE)
plot(VennCompare, doWeights=TRUE, show = list(FaceText = "sets", SetLabels = TRUE, Faces = FALSE))
plot(VennCompare)
plot(VennCompare, doWeights=TRUE)
plot(VennCompare, doWeights=TRUE, show = list(FaceText = "weight", SetLabels = TRUE, Faces = FALSE))
tex = c(1,2,3,4,5,6,7)
plot(VennCompare, doWeights=TRUE, show = list(FaceText = tex, SetLabels = TRUE, Faces = FALSE))
tex
library(Vennerable)#
Vcombo <- Venn(SetNames = c("Female", "Visible Minority", "CS Major"), Weight = c(0, 4148, 409, 604, 543, 67, 183, 146))#
plot(Vcombo)
library(Vennerable)#
Vcombo <- Venn(SetNames = c("Female", "Visible Minority", "CS Major"), Weight = c(0, 4148, 409, 604, 543, 67, 183, 146))#
plot(Vcombo, doWeights=TRUE, show = list(FaceText = "weight", SetLabels = TRUE, Faces = FALSE))
set.seed(999)
mat.a = matrix(round(rnorm(24,4,9)),3,8)
mat.a
t(apply(mat.a,1,sort))
library(NBGOF)
??nb_gof_v
up_date = "2013-04-24"#
#
path = "C:/Users/mig/Dropbox/R/Multi_sim_model"#
#path = "/Users/mig/Dropbox/R/Multi_sim_model"#
setwd(path)#
#
path1 = file.path(path, up_date)#
#dir.create(path1)#
#
## ---------------------------------------------------------------------------------------------#
library(edgeR)#
library(NBPSeq)
library(NBGOF)
library(gap)
seed = 315826#
  sim = 999#
  conf.env = 0.95#
  ## basic parameters#
  m = 1000; # 1000 genes#
  n = 6;    # 6 samples#
  s = 1e6;  # lib.sizes#
  offset = log(s);  # make sure offset for NBP functions should take the log!#
  offset   # 13.82#
  ## coefficients#
  beta = matrix(0, m, 1);  # beta0 only#
  set.seed(seed)#
  beta[,1] = rnorm(m, 5, 2) - offset;   # beta0 ~ normal (mean and a based on real RNA-Seq data)#
  beta  # m-by-1 matrix#
  ## design matrix#
  # grp.ids = rep(c(1,2), each=4);#
  # x = model.matrix(~as.factor(grp.ids));#
  # x  # 8-by-2 matrix#
  x = matrix(rep(1,n))#
  x#
  ## mean levels#
  mu = round(t(s * exp(x %*% t(beta))));#
  sum(rowSums(mu) == 0)   # 4#
  mu[rowSums(mu) == 0, ] = 1#
  sum(rowSums(mu) == 0)   # 0#
  pi = mu/s
alpha1 = -0.2  # NB1.8#
  phi0 = 0.02#
  alpha0 = log(phi0);#
  phi.nbp = phi0 * pi^alpha1;#
  range(phi.nbp)#
  cbind(mu[,1], phi.nbp[,1]);#
  # add noise#
  a = 0.1#
  set.seed(seed)  #
  phi.noi.vec = phi.nbp[ ,1] * exp(matrix(runif(m, -a, a), nr=m, nc=1))#
  phi.noi = matrix(phi.noi.vec, nr=m, nc=n)#
  range(phi.noi)#
  cbind(mu[,1], phi.noi[,1])  # make sure phi's are in reasonable range!#
  set.seed(seed)#
  y = rnbinom(m * n, mu=mu, size=1/phi.noi);#
  dim(y) = dim(mu);#
  rownames(y) = paste("g",seq(1,m),sep="")#
  colnames(y) = paste("s",seq(1,n), sep="")
ftrd.noip = nb_gof_m(counts=y,x=x, sim=sim,model.fit="edgeR-trended", min.n=100)
summary(ftrd.noip, conf.env=conf.env, data.note="NB1.8-noi(a=0.1)")
alpha1 = -0.2  # NB1.8#
  phi0 = 0.02#
  alpha0 = log(phi0);#
  phi.nbp = phi0 * pi^alpha1;#
  range(phi.nbp)#
  cbind(mu[,1], phi.nbp[,1]);#
  # add noise#
  a = 0.5#
  set.seed(seed)  #
  phi.noi.vec = phi.nbp[ ,1] * exp(matrix(runif(m, -a, a), nr=m, nc=1))#
  phi.noi = matrix(phi.noi.vec, nr=m, nc=n)#
  range(phi.noi)   #
  cbind(mu[,1], phi.noi[,1])  # make sure phi's are in reasonable range!#
  set.seed(seed)#
  y = rnbinom(m * n, mu=mu, size=1/phi.noi);#
  dim(y) = dim(mu);#
  rownames(y) = paste("g", seq(1,m), sep="")#
  colnames(y) = paste("s", seq(1,n), sep="")
ftrd.noip = nb_gof_m(counts=y,x=x, sim=sim,model.fit="edgeR-trended", min.n=100)
summary(ftrd.noip, conf.env=conf.env, data.note="NB1.8-noi(a=0.5)")
alpha1 = -0.2  # NB1.8#
  phi0 = 0.02#
  alpha0 = log(phi0);#
  phi.nbp = phi0 * pi^alpha1;#
  range(phi.nbp)#
  cbind(mu[,1], phi.nbp[,1]);#
  # add noise#
  a = 0.9#
  set.seed(seed)  #
  phi.noi.vec = phi.nbp[ ,1] * exp(matrix(runif(m, -a, a), nr=m, nc=1))#
  phi.noi = matrix(phi.noi.vec, nr=m, nc=n)#
  range(phi.noi)#
  cbind(mu[,1], phi.noi[,1])  # make sure phi's are in reasonable range!#
  set.seed(seed) #
  y = rnbinom(m * n, mu=mu, size=1/phi.noi);#
  dim(y) = dim(mu);#
  rownames(y) = paste("g",seq(1,m),sep="")#
  colnames(y) = paste("s",seq(1,n), sep="")
ftrd.noip = nb_gof_m(counts=y,x=x, sim=sim,model.fit="edgeR-trended", min.n=100)
summary(ftrd.noip, conf.env=conf.env, data.note="NB1.8-noi(a=0.9)")
a = matrix(c(1,2,NaN,4,5,3,NaN,1), nr=2)
a
a = matrix(c(NaN,NaN,4,5,NaN,NaN,1,2), nr=4)
a
a = matrix(c(5,10,NaN,NaN,4,5,NaN,NaN,1,2), nr=5)
a
a = matrix(c(5,10,NaN,NaN,4,5,3,NaN,1,2), nr=5)
a
a = matrix(c(5,10,NaN,NaN,4,5,3,NaN,NaN,2), nr=5)
a
mu = 111;#
n.rows = 1111;#
n.cols = 6;#
phi0 = 0.1;#
y0 = rnbinom(n.rows*n.cols, mu=mu, size = 1/phi0);#
dim(y0) = c(n.rows, n.cols);#
mu0 = rowMeans(y0);#
r0 = (y0 - mu0)/sqrt(mu0 + phi0 * mu0^2);#
p0 = rowSums(r0^2);#
##phi1 = 0.001;#
phi1 = 0.5;#
y1 = rnbinom(n.rows*n.cols, mu=mu, size = 1/phi1);#
dim(y1) = c(n.rows, n.cols);#
mu1 = rowMeans(y1);#
r1 = (y1 - mu1)/sqrt(mu1 + phi1 * mu1^2);#
p1 = rowSums(r1^2);#
par(mfrow=c(1, 2));#
hist(r0);#
hist(r1);#
hist(p0, nclass=20);#
hist(p1, nclass=20);#
ks.test(p0, p1);#
mean(p0>quantile(p1, 0.95));
mu = 100;#
n.rows = 1000;#
n.cols = 6;#
phi0 = 0.1;#
y0 = rnbinom(n.rows*n.cols, mu=mu, size = 1/phi0);#
dim(y0) = c(n.rows, n.cols);#
mu0 = rowMeans(y0);#
r0 = (y0 - mu0)/sqrt(mu0 + phi0 * mu0^2);#
p0 = rowSums(r0^2);#
#
phi1 = 0.001;#
#phi1 = 0.5;#
y1 = rnbinom(n.rows*n.cols, mu=mu, size = 1/phi1);#
dim(y1) = c(n.rows, n.cols);#
mu1 = rowMeans(y1);#
r1 = (y1 - mu1)/sqrt(mu1 + phi1 * mu1^2);#
p1 = rowSums(r1^2);#
#
par(mfrow=c(1, 2));#
hist(r0);#
hist(r1);#
#
hist(p0, nclass=20);#
hist(p1, nclass=20);#
#
ks.test(p0, p1);#
#
mean(p0>quantile(p1, 0.95));
mu = 100;#
n.rows = 1000;#
n.cols = 6;#
phi0 = 0.1;#
y0 = rnbinom(n.rows*n.cols, mu=mu, size = 1/phi0);#
dim(y0) = c(n.rows, n.cols);#
mu0 = rowMeans(y0);#
r0 = (y0 - mu0)/sqrt(mu0 + phi0 * mu0^2);#
p0 = rowSums(r0^2);#
#
phi1 = 0.001;#
#phi1 = 0.5;#
y1 = rnbinom(n.rows*n.cols, mu=mu, size = 1/phi1);#
dim(y1) = c(n.rows, n.cols);#
mu1 = rowMeans(y1);#
r1 = (y1 - mu1)/sqrt(mu1 + phi1 * mu1^2);#
p1 = rowSums(r1^2);#
#
#par(mfrow=c(1, 2));#
#hist(r0);#
#hist(r1);#
#
#hist(p0, nclass=20);#
#hist(p1, nclass=20);#
#
ks.test(p0, p1);#
#
mean(p0>quantile(p1, 0.95));
mu = 100;#
n.rows = 1000;#
n.cols = 6;#
phi0 = 0.1;#
y0 = rnbinom(n.rows*n.cols, mu=mu, size = 1/phi0);#
dim(y0) = c(n.rows, n.cols);#
mu0 = rowMeans(y0);#
r0 = (y0 - mu0)/sqrt(mu0 + phi0 * mu0^2);#
p0 = rowSums(r0^2);#
#
phi1 = 0.01;#
#phi1 = 0.5;#
y1 = rnbinom(n.rows*n.cols, mu=mu, size = 1/phi1);#
dim(y1) = c(n.rows, n.cols);#
mu1 = rowMeans(y1);#
r1 = (y1 - mu1)/sqrt(mu1 + phi1 * mu1^2);#
p1 = rowSums(r1^2);#
#
#par(mfrow=c(1, 2));#
#hist(r0);#
#hist(r1);#
#
#hist(p0, nclass=20);#
#hist(p1, nclass=20);#
#
ks.test(p0, p1);#
#
mean(p0>quantile(p1, 0.95));
mu = 100;#
n.rows = 1000;#
n.cols = 6;#
phi0 = 0.1;#
y0 = rnbinom(n.rows*n.cols, mu=mu, size = 1/phi0);#
dim(y0) = c(n.rows, n.cols);#
mu0 = rowMeans(y0);#
r0 = (y0 - mu0)/sqrt(mu0 + phi0 * mu0^2);#
p0 = rowSums(r0^2);#
#
phi1 = 0.001;#
#phi1 = 0.5;#
y1 = rnbinom(n.rows*n.cols, mu=mu, size = 1/phi1);#
dim(y1) = c(n.rows, n.cols);#
mu1 = rowMeans(y1);#
r1 = (y1 - mu1)/sqrt(mu1 + phi1 * mu1^2);#
p1 = rowSums(r1^2);#
#
#par(mfrow=c(1, 2));#
#hist(r0);#
#hist(r1);#
#
#hist(p0, nclass=20);#
#hist(p1, nclass=20);#
#
ks.test(p0, p1);#
#
mean(p0>quantile(p1, 0.95));
library(edgeR)
library(NBPSeq)
library(NBGOF)
library(gap)
seed = 315826#
  sim = 999#
  conf.env = 0.95#
  set.seed(seed)#
  data(arab)#
  head(arab)#
  good.arab = arab[(rowSums(arab[ ,1:3]) != 0 & rowSums(arab[ ,4:6]) != 0), ]#
  m = 1000    # number of genes subsetted#
  # m = dim(arab)[1]   # use all genes#
  samp.idx = sample(1:dim(good.arab)[1], m)  # sample m genes#
  arab.sub = good.arab[samp.idx, ]#
  head(arab.sub)  #
  y = arab.sub#
  lib.sizes = colSums(y)#
  dim(y)   #  1000  6#
  ## model matrix for arab.sub:#
  grp.ids = as.factor(c(1,1,1,2,2,2))#
  x = model.matrix(~grp.ids)#
  #x = as.matrix(rep(1,3))#
  x
y=counts
v = apply(y, 1, var)#
  mu = apply(y, 1, mean)#
  phi = (v - mu)/mu^2
grp.ids = factor(apply(x, 1, function(x) {#
        paste(rev(x), collapse = ".")#
      }), labels = seq(ncol(x)))#
      d = DGEList(counts = y, lib.size = colSums(y), group = grp.ids)#
      design = matrix(as.numeric(as.character(grp.ids)))#
      ##
      e.com = estimateGLMCommonDisp(d, design, verbose = FALSE)
com.fit = glmFit(d, design, dispersion = e.com$common.dispersion)
names(com.fit)
str(com.fit$AveLogCPM)
library(NBGOF)#
#
## basic set-up of the model:#
seed = 315825#
sim = 999#
conf.env = 0.95#
#
## basic parameter specifications:#
m = 1000; # 1000 genes#
n = 6;    # 6 samples#
s = 1e6;  # lib.sizes#
offset = log(s);  # make sure offset for NBP functions should take the log#
offset    # 13.82#
#
## simulate coefficients:#
beta = matrix(0, m, 1);  # beta0 only#
set.seed(seed)#
beta[,1] = rnorm(m, 5, 2) - offset;   # beta0 ~ normal (mean and a based on real RNA-Seq data)#
beta  # m-by-1 matrix#
#
## design matrix (single group only):#
x = matrix(rep(1,n))#
x#
#
## specify mean levels:#
mu = round(t(s * exp(x %*% t(beta))));#
sum(rowSums(mu) == 0)   # 4#
mu[rowSums(mu) == 0, ] = 1#
sum(rowSums(mu) == 0)   # 0#
pi = mu/s#
#
## simulate an m-by-n count matrix mimicking a RNA-Seq dataset:#
## simulate NB1.8 data with random uniform noise added to the dispersion#
alpha1 = -0.2  # NB1.8#
phi0 = 0.02#
alpha0 = log(phi0)#
phi.nbp = phi0 * pi^alpha1#
range(phi.nbp)#
cbind(mu[,1], phi.nbp[,1]);#
#
## add noise:#
a = 0.1#
set.seed(seed)#
phi.noi.vec = phi.nbp[ ,1] * exp(matrix(runif(m, -a, a), nr=m, nc=1))#
phi.noi = matrix(phi.noi.vec, nr=m, nc=n)#
range(phi.noi)#
cbind(mu[,1], phi.noi[,1])  # make sure phi's are in reasonable range#
#
## generate NBP response with added noise:#
set.seed(seed)#
y = rnbinom(m * n, mu=mu, size=1/phi.noi)#
dim(y) = dim(mu)#
rownames(y) = paste("g", seq(1,m), sep="")#
colnames(y) = paste("s", seq(1,n), sep="")#
plot(mu, phi.noi, log="xy")#
#
## GOF tests for different dispersion models:#
## CAUTION: may be time-consuming depending on the size of data and simulations#
fnbp.noip = nb_gof_m(counts=y, x=x, sim=sim, model="NBP")
irls.nb
estimate.dispersion
library(NBPSeq)
estimate.dispersion
library(NBGOF)#
#
## basic set-up of the model:#
seed = 315825#
sim = 999#
conf.env = 0.95#
#
## basic parameter specifications:#
m = 1000; # 1000 genes#
n = 6;    # 6 samples#
s = 1e6;  # lib.sizes#
offset = log(s);  # make sure offset for NBP functions should take the log#
offset    # 13.82#
#
## simulate coefficients:#
beta = matrix(0, m, 1);  # beta0 only#
set.seed(seed)#
beta[,1] = rnorm(m, 5, 2) - offset;   # beta0 ~ normal (mean and a based on real RNA-Seq data)#
beta  # m-by-1 matrix#
#
## design matrix (single group only):#
x = matrix(rep(1,n))#
x#
#
## specify mean levels:#
mu = round(t(s * exp(x %*% t(beta))));#
sum(rowSums(mu) == 0)   # 4#
mu[rowSums(mu) == 0, ] = 1#
sum(rowSums(mu) == 0)   # 0#
pi = mu/s#
#
## simulate an m-by-n count matrix mimicking a RNA-Seq dataset:#
## simulate NB1.8 data with random uniform noise added to the dispersion#
alpha1 = -0.2  # NB1.8#
phi0 = 0.02#
alpha0 = log(phi0)#
phi.nbp = phi0 * pi^alpha1#
range(phi.nbp)#
cbind(mu[,1], phi.nbp[,1]);#
#
## add noise:#
a = 0.1#
set.seed(seed)#
phi.noi.vec = phi.nbp[ ,1] * exp(matrix(runif(m, -a, a), nr=m, nc=1))#
phi.noi = matrix(phi.noi.vec, nr=m, nc=n)#
range(phi.noi)#
cbind(mu[,1], phi.noi[,1])  # make sure phi's are in reasonable range#
#
## generate NBP response with added noise:#
set.seed(seed)#
y = rnbinom(m * n, mu=mu, size=1/phi.noi)#
dim(y) = dim(mu)#
rownames(y) = paste("g", seq(1,m), sep="")#
colnames(y) = paste("s", seq(1,n), sep="")#
plot(mu, phi.noi, log="xy")#
#
## GOF tests for different dispersion models:#
## CAUTION: may be time-consuming depending on the size of data and simulations#
fnbp.noip = nb_gof_m(counts=y, x=x, sim=sim, model="NBP")
library(gap)
?qqunif
u_obs <- runif(1000)#
r <- qqunif(u_obs,pch=21,bg="blue",bty="n")#
u_exp <- r$y#
hits <- u_exp >= 2.30103#
points(r$x[hits],u_exp[hits],pch=21,bg="green")
exdi = rexp(n=200,rate=0.5)#
y.exdi=vector(length=2000)#
for(i in 1:2000){#
	y.exdi[ i ]=mean(exdi)#
	}
y.exdi
for(i in 1:2000){#
	y.exdi[ i ]=mean(rexp(n=200,rate=0.5))#
	}
y.exdi
mean(y.exdi)
library(car)#
set.seed(9)#
u_obs <- runif(100)#
windows()#
  qqPlot(u_obs, distribution="unif")
seed = 539768
library(NBGOF)
set.seed(seed)
data(arab)
arab.good = arab[(rowSums(arab[ ,1:3]) != 0 & rowSums(arab[ ,4:6]) != 0), ]
dim(arab.good)
sum(CV(counts=arab.good, grp.ids=as.factor(c(1,1,1)), cutoff=1.5)$gene.idx)
sum(CV(counts=arab.good, grp.ids=as.factor(c(1,1,1,2,2,2)), cutoff=1.5)$gene.idx)
17738/22376
CV.obj = CV(counts=arab.good, grp.ids=as.factor(c(1,1,1,2,2,2)), cutoff=1.5)
sum(CV.obj$gene.idx)   # 17738
CV.obj/dim(arab.good)[1]  # 79%
sum(CV.obj$gene.idx)/dim(arab.good)[1]  # 79%
names(CV.obj)
hist(CV.obj$cv.mat)
quantile(CV.obj$cv.mat)
head(CV.obj$cv.mat)
sum(CV.obj$cv.mat > 1.5)
head(CV.obj$cv.mat)
hist(CV.obj$cv.mat)
rowMeans
rowVars
rowVar
MEAN = function(counts, grp1, grp2){#
	return(list(mean.1 = rowMeans(counts[, grp1]),#
	mean.2 = rowMeans(counts[, grp2])))#
}#
#
VAR = function(counts, grp1, grp2){#
	return(list(#
	var.1 = apply(counts[,grp1], 1, var),#
	var.2 = apply(counts[,grp2], 1, var)))#
}#
#
grp1 = 1:3#
grp2 = 4:6#
mean.mat = MEAN(arab.good, grp1, grp2)
mean.mat
dim(mean.vec)
dim(mean.mat)
str(mean.mat)
var.mat = VAR(arab.good, grp1, grp2)
plot(mean.mat$mean.1, var.mat$var.1)
plot(mean.mat$mean.1, var.mat$var.1, log="xy")
abline(1,0)
plot(mean.mat$mean.1, var.mat$var.1, log="xy")
abline(0,1)
abline(0,1, col="red", type="dashed")
plot(mean.mat$mean.1, var.mat$var.1, log="xy")
abline(0,1, col="red", lty="dashed")
plot(mean.mat$mean.1, sqrt(var.mat$var.1), log="xy")
abline(0,1, col="red", lty="dashed")
path = "/Users/mig/OSU/R_pkg/NBGOF_dir/NBGOF"#
# dir.create(path)#
setwd(path)#
#
# create a sub-directory called "R" under "NBGOF" folder [run only once!]#
# create a sub-directory called "src" under "NBGOF" folder [run only once!]#
# create a sub-directory called "inst" under "NBGOF" folder [run only once!]#
# dir.create(file.path(path, "R"))#
# dir.create(file.path(path, "src"))#
# dir.create(file.path(path, "inst"))#
#
library(devtools)
load_all(path)#
# Loading NBGOF#
search()  # "package:NBGOF" is available in the search path#
# Your development routine is simply edit/load_all/test. There's no build step!#
#
## ----------------------------------------------------------------------------------#
# convert roxygen comments #' into official .Rd document files:#
# document() will update namespace directives!#
document(file.path(path))   # re-run document() if you change the document#
check_doc(file.path(path))
build(path)#
# [1] "/Users/mig/OSU/R_Pkg/NBGOF_dir"#
#
# install the package#
install.packages("../NBGOF_0.2.7.tar.gz", repo=NULL, type="source")
